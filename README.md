# 手绘草图分类问题

##### 林宇欣：220030910004， 胡屹垚：20030910016， 王祎雯：220030910002

## 1. 项目简介

​		手绘草图（freehand sketch）是一种形式简单但蕴含丰富信息的艺术形式，通过简洁的线条能表现出强烈的风格以及传递鲜明的信息。虽然人类能够轻松地从简笔画中获取主要的信息，但是这个任务对于机器来说非常有挑战。这种挑战主要来自于手绘草图含义的模糊性、同类对象在几何表达上的差异性，以及模型的输入图片缺乏丰富的纹理特征。因此本项目旨在实验比较不同模型对手绘草图的分类效果。本项目实践了传统分类模型和深度神经网络模型，其中传统模型包括了SVM（Support Vector Machine）、KNN（K Nearest Neighbor）和MLP（Multi Layer Perceptron）方法，深度神经网络模型包括了ResNet和VGG网络。【比较结果待补充】

## 2. 相关工作 

​		手绘草图识别的难点有3个。首先，对于相同类别的图片，人对于该类别的关键信息理解不同，并且根据直觉创造出内涵模糊的图形，这种模糊性甚至对人的识别来说也是较为困难的。其次，手绘草图根据绘画者的不同，其艺术表达风格也不同，因此同种类别下草图的表现形式差异也非常大。最后，和照片的识别相比，手绘草图没有颜色和纹理的信息，同时画面中也存在大量相同的留白，因此图像信息相对之下更稀少。

​		针对手绘草图识别任务的模型可以按照模型输入的不同分为三类。第一类是将手绘草图的分类视为图像分类任务，即模型的输入是像素图片。像素图片的分类可以用传统的分类方法，如SVM和KNN来实现。也可以用卷积神经网络进行学习和分类。早期使用卷积神经网络的方法效果并不出众的一个原因在于没有足够的数据集来支撑卷积网络的训练。而另外一个原因则是由于手绘图和照片的区别，导致为照片分类设计的卷积网络在手绘草图的分类上表现并不突出。第二类是基于笔画顺序设计的分类模型，这类模型的输入是人在绘制时按照时间先后顺序画出的线条序列。这类模型认为手绘草图的重要特性是笔画的线条和绘制的时序信息，因此选择笔画顺序为模型输入。这类模型为了利用信息中的时序信息，通常采用循环神经网络。而第三类模型是同时利用像素图像信息和笔画顺序信息进行分类，希望充分挖掘和利用手绘草图中的信息。例如Sktech-a-Net[1]，是将传统的卷积神经网络进行了修改，考虑到了人在绘制时倾向于先画总体特征，再画细节特征的习惯，因此对多层次的特征进行了提取和融合。而Sketch-R2CNN[2]则是采用了卷积神经网络和循环神经网络两个分支，使用卷积神经网络将笔画顺序特征转换为多通道的点特征，再使用卷积神经网络进行识别分类。

## 3. 数据集介绍 

​		本项目使用的数据集为QuickDraw数据集。QuickDraw数据集收集了来自Quick, Draw！游戏中用户在20秒内所画的指定类别的手绘草图。在这个数据集中，每个草图样本是以笔画顺序的形式进行存储的。草图样本由一系列点组成，每个点由5个特征$(\Delta x,\Delta y, p_1, p_2, p_3)$构成，这5个特征依次表示了当前笔画相对于上一笔画在画布上的偏移量$(\Delta x, \Delta y)$，以及当前笔画的特征状态。其中$p_1$表示了当前笔画正在接触画布，并且会与下一个点连接起来；$p_2$表示在当前笔画之后笔将被抬起；而$p_3$表示整个绘制已经结束。原始的QuickDraw数据集共有345个种类的手绘草图，每个种类下均有70000张训练集样本，2500验证集样本，和2500个测试集样本。本项目使用的数据是QuickDraw原始数据集中的25个动物草图种类，分别为牛、熊猫、狮子、老虎、浣熊、猴子、刺猬、斑马、马、猫头鹰、大象、松鼠、羊、狗、熊、袋鼠、鲸鱼、鳄鱼、犀牛、企鹅、骆驼、火烈鸟、长颈鹿、猪和猫。

​		对于原始数据的笔画序列，我们选择将其转换为28*28像素大小的png格式图片作为模型的输入。序列到图片的转换我们采用了https://github.com/CMACH508/RPCL-pix2seq中的方法。

## 4. 研究方法

### 4.1 传统分类方法

​		传统的分类方法有SVM和KNN算法，这两个方法作为经典的有监督学习模型，应用场景非常广泛，因此本项目选择采用这两个算法进行实验。其中SVM算法作为本次实验的基线实验进行测试。而MLP模型虽然作为神经网络模型区别于以上提到的两个模型，但由于他的结构相对简单，并且网络的每层之间只采用了全连接的形式，因此在本项目中把它也归入了传统的分类方式。

​		同时，为了更好地了解数据集，我们还使用了TSNE对数据的分布进行了可视化。类比于同样维度，同样是黑白图片，同样是手写的MINST数据集，降维手段在MINST数据集上能帮助提高分类器的准确率，因此我们也选择在本项目的数据集上进行降维，探究降维对手绘草图分类任务是否有帮助。

### 4.2 Deep Learning

#### 4.2.1 ResNet

#### 4.2.2 VGG



## 5. 实验分析

### 5.1 传统分类模型

​		传统方法的实验中，我们选择将28*28的像素图片展平，将784\*1维的数据作为模型的输入进行实验。

#### 5.1.1 SVM

​		由于实验机器的内存和时间限制，本实验无法使用每种动物分类下的全部草图，因此本实验采取了进一步缩减训练集样本数量的策略，采取随机抽取再混合的方式生成新的训练集，并在测试得出最佳实验参数后，对内存承受范围内的不同大小的训练集也进行了测试。

​		首先我们从每个分类下的动物中抽取了500张图片进行混合生成了大小为5000的训练集，用于确定SVM模型的最佳参数。我们测试了不同的惩罚项系数C，和两种不同的核函数，其训练结果如下图所示。从图中可以看出，线性SVM在不同惩罚项系数下的准确率几乎没有差别，可以认为线性SVM在该分类任务中的效果非常差，而rbf核在C=1时取得了最高的准确率0.476256。因此后续关于训练集大小的实验中我们采用了这组超参数。

<img src=".\figs\SVM-C-Kernel.png" alt="SVM-C-Kernel" style="zoom: 67%;" />

​		其次，我们按照上述相同的方法，分别从每个分类下的动物中抽取了100，500，1000，2000，5000个样本混合组成了训练集进行训练和测试，其训练结果如下图所示。从图中可以看出，SVM的准确率在随着训练集的增大而增大，因此可以推测当内存和算力足够时，SVM的准确率可以达到高于**0.597408**的效果。但是需要注意的是，当训练集样本的增多，训练时长也在快速增长，并且这个增长并不是线性的。

<img src="D.\figs\SVM Trainset Size.png" alt="SVM Trainset Size" style="zoom: 67%;" />

#### 5.1.2 KNN

​		对于KNN算法，由于本实验的场景下我们已知动物分类共有25种，因此我们选择直接指定超参数k=25。对KNN算法，我们实验了三种距离度量方式。同时，由于机器内存和时间限制，我们也采取了减小训练集大小，测试不同大小训练集结果的方式进行实验。

​		首先我们从每个分类下的动物中抽取了10000张图片进行混合生成了大小为250000的训练集，用于确定KNN模型的最佳距离度量方式。实验结果如下表所示。从结果中可以看出，欧式距离度量是最适合本项目场景的，其拥有最高的准确率和最快的运行时间。因此之后关于训练集大小实验也采用与之相同的超参数。

| 距离度量      | 准确率   | 运行时长/s |
| ------------- | -------- | ---------- |
| **manhattan** | 0.3876   | 9117.74    |
| **euclidean** | 0.454848 | 480.92     |
| **chebyshev** | 0.29528  | 5735.5     |

​		其次，我们按照上述相同的方法，分别从每个分类下的动物中抽取了100，500，1000，2000，5000，10000个样本混合组成了训练集进行训练和测试，其训练结果如下图所示。从下图中可以看出，KNN的准确率在随着训练样本的增多而增大，因此可以合理推断，在内存足够时，KNN的准确率可以达到高于**0.454848**的效果。同时，与SVM相比，KNN的运行时间明显更短，并且其时间是随着训练集样本数量线性增长的。虽然KNN相比SVM的分类效果更差，但是在考虑运行时间成本上，KNN具有好的表现。

<img src=".\figs\KNN Trainset Size.png" alt="KNN Trainset Size" style="zoom:67%;" />

#### 5.1.3 MLP

​		对于MLP模型，我们测试了不同的网络宽度，深度以及迭代轮次。同时，由于机器内存和时间限制，我们也采取了减小训练集大小的策略，我们在每个种类的动物中选取了5000张草图样本组成了新的训练集进行训练。

​		首先，我们对单隐层不同宽度的MLP网络在不同迭代轮次下的性能进行了测试。考虑到MLP运行结果的不稳定性，我们的测试结果是重复3次运行后的平均准确率。测试结果如下所示。从图中可以看出，随着网络宽度的加深，MLP的准确率在提高，但是可以可以看出，每增加100个神经元，每次模型准确率的提升在减少。除此之外，可以看出模型的准确率随着迭代轮次的增加在上下震荡，因此后续实验中考虑采用最少的5000轮进行迭代。

<img src=".\figs\MLP width.png" alt="MLP width" style="zoom:67%;" />

​		其次我们测试了隐层每层500个神经元的情况下，存在1层，2层和3层隐层的网络效果，其结果如下表所示。可以看出在两个隐层为500时，准确率最高只有**0.29023**。MLP模型与SVM和KNN相比，效果更差。有部分原因是复杂的网络模型需要更大量的样本进行训练，但由于机器的限制，本项目只能支持MLP使用与SVM和KNN同等大小训练集进行训练。同时，MLP模型的输出结果并不稳定，经常会出现在测试集上的表现为随机选择的期望大小的正确率。此外，MLP的全连接结构并不能获取图像中空间有关的信息，因此整体网络结构并不适合此场景。

| 网络结构   | [500]   | [500,500] | [500,500,500] |
| ---------- | ------- | --------- | ------------- |
| **准确率** | 0.23825 | 0.29023   | 0.11127       |

#### 5.1.4 PCA & TSNE

​		首先，我们采用了TSNE对原始数据进行了可视化，其可视化结果如下图所示。可以看出，对于25类的分类任务，将数据拉至2维后无法直观地看出同类样本的聚集。

<img src=".\figure\原始数据的分布.png" alt="原始数据的分布" style="zoom:50%;" />

​		其次，我们使用PCA，对数据进行降维，我们选择了0.999，0.99，0.9作为方差的阈值，对原始数据进行了降维，并使用分类结果较好的SVM和KNN进行分类，两个模型使用的参数均为上述实验中最优超参的参数，其分类结果如下表所示，PCA降维后的数据以及原始数据和PCA降维后数据的对比如下两图所示。可以看出，PCA通过筛选，能成功淘汰部分维度，但是降维后SVM和KNN的准确率均大幅度下降。同时，由TSNE的结果可以看出，PCA并未有效辅助分类，不同种类的样本依旧均匀地分散在空间中。因此可以认为，降维策略在手绘草图分类任务中并不适用。虽然手写数字和手绘草图在某些方面有一定的相似性，但是明显手写数字存在更高的规范性，样本之间的差异性更小，而手绘草图的样本差异性明显更大，分类数目也更多，因此使得PCA降维策略在两个数据集上起到了相反的作用。更进一步来说，784*1维的特征对于这个分类任务来说是不足以支撑它进行准确分类的，因此在模型中，我们不仅不需要降维，反而还需要对模型进行升维，即通过卷积操作来获取图像中的空间信息，或者额外考虑笔画序列的时序信息。

| 方差阈值 | 数据维度 | SVM准确率 | KNN准确率 |
| -------- | -------- | --------- | --------- |
| 0.999    | 637      | 0.26344   | 0.125597  |
| 0.99     | 548      | 0.26376   | 0.114304  |
| 0.9      | 308      | 0.26512   | 0.123456  |

<img src=".\figure\PCA降维后的分布.png" alt="PCA降维后的分布" style="zoom:50%;" />

<img src=".\figure\降维和未降维的数据.png" alt="降维和未降维的数据" style="zoom:50%;" />

### 5.2 深度学习模型



## 6. 总结与展望



## 7. 参考文献

1. Yu Q ,  Yang Y ,  Liu F , et al. Sketch-a-Net: A Deep Neural Network that Beats Humans[J]. International Journal of Computer Vision, 2017, 122(3):411-425.
2. Li L , Zou C , Zheng Y , et al. Sketch-R2CNN: An RNN-Rasterization-CNN Architecture for Vector Sketch Recognition[J]. IEEE Transactions on Visualization and Computer Graphics, 2020, PP(99):1-1.

